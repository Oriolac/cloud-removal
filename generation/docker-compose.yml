services:
  laclasse-inference-inference:
    container_name: laclasse-inference-container
    image: laclasse-inference:latest
    shm_size: '50gb'
    build: .
    tty: true
    stdin_open: true # docker run -i // removing it has no effect
    #command: python main.py cnn configs/carla.yml
    command: python inference.py 6362419456364c2588fafd304b898136 residual /output/residual/ 1
    #command: python inference.py 4b46262d713346298f63112c55ce596a Regina /output/regina/ 1
    volumes:
      - /home/oriol.alas@local.eurecat.org/TFM/projects/generation_cnn3/configs:/app/configs
      - /data/docker/volumes/laclasse/SEN12MS-CR/:/data/
      - /data/docker/volumes/laclasse/runs/:/runs/
      - /data/docker/volumes/laclasse/inputs/:/inputs/
      - /data/docker/volumes/laclasse/output/:/output/
    labels:
      maintainer: "oriol.alas@eurecat.org"
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [ gpu ]
